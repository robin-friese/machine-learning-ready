{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS LIBRARY\n",
    "\n",
    "`Another Open Source Python Library used for working with (at least) 2-dimensional Data`\n",
    "\n",
    "Here's what the People behind Pandas say about it (https://pandas.pydata.org/about/ from March, 2021)...\n",
    "\n",
    "**Mission** <br>\n",
    "\n",
    "\"pandas aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. <br> Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language.\"\n",
    "\n",
    "**Library Highlights** <br>\n",
    "\n",
    "* A fast and efficient `DataFrame` object for data manipulation with integrated indexing <br>\n",
    "<br>\n",
    "* Tools for `reading and writing data` between in-memory data structures and different formats: <br> CSV and text files, Microsoft Excel, SQL databases, and the fast HDF5 format\n",
    "\n",
    "[...]\n",
    "\n",
    "* Intelligent `label-based` slicing, fancy indexing, and subsetting of large data sets\n",
    "\n",
    "[...]\n",
    "\n",
    "\n",
    "* `Aggregating or transforming data` with a powerful group by engine allowing split-apply-combine operations on data sets <br>\n",
    "<br>\n",
    "* High performance `merging and joining` of data sets\n",
    "\n",
    "[...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Import Pandas Library`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Creating Pandas Series for 1-dimensional Data (aka Column Vector)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series from Integer/Float/String\n",
    "series = pd.Series('A', index=[1, 2, 3, 4, 5])\n",
    "print(series)\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series from List\n",
    "list_for_series = [x for x in range(0, 50+1, 5)]\n",
    "series = pd.Series(list_for_series, index=None)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series from Dictionary\n",
    "dict_for_series = {'A': 1, 'B': 2, 'C': 3}\n",
    "series = pd.Series(dict_for_series, index=None)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series from NumPy Array\n",
    "import numpy as np\n",
    "array_for_series = np.random.rand(5)\n",
    "series = pd.Series(array_for_series, index=None, name='Random')\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Creating Pandas DataFrame for 2-dimensional Data (aka Matrix)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from Dictionary of Lists\n",
    "dict_lists_for_df = {\n",
    "    'Capital': ['A', 'B', 'C'],\n",
    "    'Small': ['a', 'b', 'c']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict_lists_for_df, index=None)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from Dictionary of NumPy Arrays\n",
    "dict_arrays_for_df = {\n",
    "    'Zeros': np.zeros(5),\n",
    "    'Ones': np.ones(5)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict_arrays_for_df, index=None)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from 2D-Array\n",
    "array2D_for_df = np.eye(10, dtype=np.int64)\n",
    "\n",
    "list_columns = ['Column_' + str(i) for i in range(0,10)]\n",
    "\n",
    "df = pd.DataFrame(array2D_for_df, index=None, columns=list_columns)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from named Series\n",
    "series_for_df = pd.Series(np.random.rand(5), index=None, name='Random')\n",
    "\n",
    "df = pd.DataFrame(series_for_df, index=None)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty DataFrame with named Columns\n",
    "df = pd.DataFrame(index=None, columns=['Column1', 'Column2', 'Column3'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Indexing (= Selecting Data from) a DataFrame` using `loc` and `iloc`\n",
    "\n",
    "`Note:` `loc` is used for `label-based` and `iloc` is used for `integer-based Indexing` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "m = 5\n",
    "\n",
    "list_idx = ['Row_' + str(i) for i in range(0,n)]\n",
    "list_col = ['Col_' + str(i) for i in range(0,m)]\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(100, size=(n,m)), index=list_idx, columns=list_col)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# Select Row by Label (loc)\n",
    "series = df.loc['Row_3', :]\n",
    "print(' ')\n",
    "print('Row_3 as Pandas Series')\n",
    "print(series)\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select Row by Integer (iloc)\n",
    "series = df.iloc[4, :]\n",
    "print(' ')\n",
    "print('Row_3 as Pandas Series')\n",
    "print(series)\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select Column by Label (loc)\n",
    "series = df.loc[:, 'Col_4']\n",
    "print(' ')\n",
    "print('Col_4 as Pandas Series')\n",
    "print(series)\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select Column by Integer (iloc)\n",
    "series = df.iloc[:, -1]\n",
    "print(' ')\n",
    "print('Col_4 as Pandas Series')\n",
    "print(series)\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select multiple Rows and Columns by Label (loc)\n",
    "df_sel = df.loc['Row_0':'Row_4', ['Col_1', 'Col_3']]\n",
    "print(' ')\n",
    "print('Rows 0-4 and Cols 1,3 as Pandas DataFrame')\n",
    "display(df_sel)\n",
    "print(type(df_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select multiple Rows and Columns by Integer (iloc)\n",
    "df_sel = df.iloc[:3, -3:]\n",
    "print(' ')\n",
    "print('First three Rows and last three Columns as Pandas DataFrame')\n",
    "display(df_sel)\n",
    "print(type(df_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select single Value by Label (loc)\n",
    "value = df.loc['Row_8', 'Col_3']\n",
    "print(' ')\n",
    "print('Single Value in Row_8 and Col_3 as NumPy Integer')\n",
    "print(value)\n",
    "print(type(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select single Value by Integer (iloc)\n",
    "value = df.iloc[1,0]\n",
    "print(' ')\n",
    "print('Single Value in Row_1 and Col_0 as NumPy Integer')\n",
    "print(value)\n",
    "print(type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Selecting Rows` using `head` and `tail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first three Rows\n",
    "df_sel = df.head(3)\n",
    "display(df_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select last two Rows\n",
    "df_sel = df.tail(2)\n",
    "display(df_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Selecting Rows` using `Boolean Masking`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select Rows\n",
    "df_sel = df[df['Col_0'] > 50]\n",
    "print(' ')\n",
    "print('All Rows with Col_0 > 50')\n",
    "display(df_sel)\n",
    "print(type(df_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Boolean Masking with multiple Conditions`\n",
    "\n",
    "`Note: You must use Square Brackets for each Condition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "\n",
    "# Select Rows\n",
    "df_sel = df[(df['Col_0'] > 50) & (df['Col_1'] < 30)]\n",
    "print(' ')\n",
    "print('All Rows with Col_0 > 50 AND Col_1 < 30')\n",
    "display(df_sel)\n",
    "print(type(df_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Simplified Column Selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df['Col_1']\n",
    "\n",
    "print(series)\n",
    "print(type(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sel = df[['Col_1', 'Col_2']]\n",
    "\n",
    "display(df_sel)\n",
    "print(type(df_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Notice: It is good Practice to use copy() whenever you index a DataFrame` <br> `...no matter if you use loc, iloc, Boolean Masking or a simplified Version of Indexing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "df_sel = df[['Col_1', 'Col_2']].copy()\n",
    "\n",
    "display(df_sel)\n",
    "print(type(df_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Selecting the Index from a DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = df.index\n",
    "\n",
    "print(index)\n",
    "print(type(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Resetting the Index of a DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.reset_index()\n",
    "\n",
    "display(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the old Index\n",
    "df_new = df.reset_index(drop=True)\n",
    "\n",
    "display(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Returning the Dimensions of a DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Dimensions\n",
    "print('# of Dimensions:', df.ndim)\n",
    "\n",
    "# Number of Rows\n",
    "print('# of Rows:', len(df))\n",
    "\n",
    "# Number of Columns\n",
    "print('# of Columns:', len(df.columns))\n",
    "\n",
    "# Shape\n",
    "print('Shape:', df.shape)\n",
    "\n",
    "# Number of Items (Size)\n",
    "print('Number of Items (Size):', df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Checking whether a DataFrame is empty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sort DataFrame by Column(s)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame\n",
    "list_cols = ['x' + str(i) for i in range(1, 10+1)]\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(3, size=(10, 10)), index=None, columns=list_cols)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by x1 ascending\n",
    "df_sorted = df.sort_values(by=['x1'], ascending=True)\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by x9 descending \n",
    "df_sorted = df.sort_values(by=['x9'], ascending=False)\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by x2 descending and x3 ascending\n",
    "df_sorted = df.sort_values(by=['x2', 'x3'], ascending=[False, True])\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dropping Duplicates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates including all Columns\n",
    "print('# Rows before dropping Duplicates:', len(df))\n",
    "df_dropped = df.drop_duplicates()\n",
    "print('# Rows after dropping Duplicates:', len(df_dropped))\n",
    "display(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates including a Subset of Columns\n",
    "print('# Rows before dropping Duplicates:', len(df))\n",
    "df_dropped = df.drop_duplicates(subset=['x1', 'x2', 'x3'], keep='first')\n",
    "print('# Rows after dropping Duplicates:', len(df_dropped))\n",
    "display(df_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Creating new Columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Column with constant Value\n",
    "df['n1'] = np.NaN\n",
    "df['n2'] = 3\n",
    "df['n3'] = -1\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Column derived from other Columns\n",
    "df['n4'] = df['n2'] + df['n3']\n",
    "df['n5'] = df['x1']**2 - 2*df['x2'] + 1\n",
    "df['n6'] = np.ceil((df['n2'] - df['x1']) / 2).astype(int)\n",
    "df['n7'] = np.where(\n",
    "    (df['x2'] > 0) | (df['x3'] > 0),\n",
    "    True, False\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dropping Columns` using `drop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(columns=['n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7'])\n",
    "\n",
    "display(df_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dropping Columns` using `loc` (`Negative Selection`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.loc[:, ~df.columns.str.startswith('n')]\n",
    "\n",
    "display(df_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Aggregation Functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_df = {\n",
    "    'x1': [-1, 0, 1],\n",
    "    'x2': [ 0, 0, 0],\n",
    "    'x3': [ 1, 0, np.NaN],\n",
    "    'x4': [ 0, 2, 0],\n",
    "    'x5': [ 1, -2, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict_for_df, index=None)\n",
    "\n",
    "display(df)\n",
    "\n",
    "# Maximum per Column\n",
    "print(' ')\n",
    "print('Maxium per Column:')\n",
    "print(df.max(axis=0))\n",
    "\n",
    "# Minimum per Row\n",
    "print(' ')\n",
    "print('Minimum per Row:')\n",
    "print(df.min(axis=1))\n",
    "\n",
    "# Mean per Column\n",
    "print(' ')\n",
    "print('Mean per Column:')\n",
    "print(df.mean(axis=0))\n",
    "print(df.mean(axis=0, skipna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Creating new Columns` using `Aggregation Functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of Column 'x4'\n",
    "df['ColMax_x4'] = df.loc[:, 'x4'].max(axis=0)\n",
    "\n",
    "# ...or\n",
    "df['ColMax_x4_v2'] = df.max(axis=0).loc['x4']\n",
    "\n",
    "# Maximum per Row over Columns 'x1' to 'x5'\n",
    "df['RowMaxAll'] = df.loc[:, 'x1':'x5'].max(axis=1)\n",
    "\n",
    "# Maximum per Row over Columns 'x1' and 'x2'\n",
    "df['RowMax_x1_x2'] = df.loc[:, ['x1', 'x2']].max(axis=1)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Creating new Columns` using `Shift Function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "array_for_df = np.random.randint(100, size=(10, 3))\n",
    "\n",
    "indices_for_df = pd.date_range(datetime.date.today(), periods=10).tolist()\n",
    "\n",
    "columns_for_df = ['A', 'B', 'C']\n",
    "\n",
    "df = pd.DataFrame(array_for_df, index=indices_for_df, columns=columns_for_df)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lag 1-Values for Column A\n",
    "df_shift = df.copy()\n",
    "\n",
    "df_shift['A_lag1'] = df_shift['A'].shift(1)\n",
    "    \n",
    "display(df_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lag 1 and 2-Values for Column B\n",
    "df_shift = df.copy()\n",
    "\n",
    "for lag in [1,2]:\n",
    "    df_shift['B_lag' + str(lag)] = df_shift['B'].shift(lag)\n",
    "    \n",
    "display(df_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lead 1, 2 and 3-Values for Columns A, B and C\n",
    "df_shift = df.copy()\n",
    "\n",
    "for col in df_shift.columns:\n",
    "    for lead in [-1, -2, -3]:\n",
    "        df_shift[col + '_lead' + str(-lead)] = df_shift[col].shift(lead)\n",
    "    \n",
    "display(df_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Grouping DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "dates  = pd.date_range(datetime.date(2020,1,1), periods=365).tolist()\n",
    "months = pd.date_range(datetime.date(2020,1,1), periods=365).month.tolist()\n",
    "sales  = np.random.randint(100000, size=(365))\n",
    "\n",
    "dict_for_df = {\n",
    "    'Month': months,\n",
    "    'Sales': sales\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(dict_for_df, index=dates)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Sales by Month\n",
    "df_grouped = df.groupby('Month').agg({'Sales': ['sum', 'mean']})\n",
    "\n",
    "display(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Concatenating DataFrames` with identical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two DataFrames with identical Columns\n",
    "dict1 = {\n",
    "    'A': ['A0', 'A1', 'A2', 'A3', 'A4'],\n",
    "    'B': ['B0', 'B1', 'B2', 'B3', 'B4'],\n",
    "    'C': ['C0', 'C1', 'C2', 'C3', 'C4']\n",
    "}\n",
    "\n",
    "dict2 = {\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2'],\n",
    "    'C': ['C0', 'C1', 'C2']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(dict1, index=None)\n",
    "df2 = pd.DataFrame(dict2, index=None)\n",
    "\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `append`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will give duplicate Index Values\n",
    "df_joined = df1.append(df2)\n",
    "\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will \"ignore\" Index\n",
    "df_joined = df1.append(df2, ignore_index=True)\n",
    "\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use `concat` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating along Axis 0 (= Appending)\n",
    "list_df_to_concat = [df1, df2]\n",
    "\n",
    "df_joined = pd.concat(list_df_to_concat, axis=0, ignore_index=True)\n",
    "\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Concatenating DataFrames` with identical Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two DataFrames with identical Rows \n",
    "dict1 = {\n",
    "    'A': ['A0', 'A1', 'A2', 'A3', 'A4'],\n",
    "    'B': ['B0', 'B1', 'B2', 'B3', 'B4'],\n",
    "    'C': ['C0', 'C1', 'C2', 'C3', 'C4']\n",
    "}\n",
    "\n",
    "dict2 = {\n",
    "    'D': ['D0', 'D1', 'D2', 'D3', 'D4'],\n",
    "    'E': ['E0', 'E1', 'E2', 'E3', 'E4']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(dict1, index=None)\n",
    "df2 = pd.DataFrame(dict2, index=None)\n",
    "\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concatenate along Axis 1\n",
    "df_joined = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Concatenating DataFrames` with different Rows and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two DataFrames with different Rows and Columns\n",
    "dict1 = {\n",
    "    'X': ['X0', 'X1', 'X2', 'X3', 'X4'],\n",
    "    'Y': ['Y0', 'Y1', 'Y2', 'Y3', 'Y4'],\n",
    "    'A': ['A0', 'A1', 'A2', 'A3', 'A4']\n",
    "}\n",
    "\n",
    "dict2 = {\n",
    "    'X': ['X0', 'X1', 'X2', 'X3'],\n",
    "    'Y': ['Y0', 'Y1', 'Y2', 'Y3'],\n",
    "    'Z': ['Z0', 'Z1', 'Z2', 'Z3']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(dict1, index=None)\n",
    "df2 = pd.DataFrame(dict2, index=None)\n",
    "\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `concat` along Axis 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will append Rows and fill non-existing Columns with NaN\n",
    "df_joined = pd.concat([df1, df2], axis=0, ignore_index=True, sort=True)\n",
    "\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Merging DataFrames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Left Join`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fact Table\n",
    "df = pd.DataFrame(dict({'city_id': np.random.randint(1, 4,    size=(5)),\n",
    "                        'x1'     : np.random.randint(0, 1000, size=(5)),\n",
    "                        'x2'     : np.random.randint(0, 1000, size=(5)),\n",
    "                        'x3'     : np.random.randint(0, 1000, size=(5)),}), \n",
    "                  index=None)\n",
    "# Dimension Table\n",
    "df_city = pd.DataFrame(dict({'city_id': [1, 2, 3], \n",
    "                             'city_text': ['Berlin', 'Hamburg', 'München']}), \n",
    "                       index=None)\n",
    "\n",
    "display(df)\n",
    "display(df_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df.loc[:, 'city_text'] = pd.merge(df, df_city, \n",
    "                                  how='left', left_on='city_id', right_on='city_id')\n",
    "\n",
    "df.sort_index(axis=1, inplace=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Inner Join`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(dict({'customer_id': [1, 2, 3, 4, 5],\n",
    "                         'sex': ['male', 'male', 'female', 'male', 'female']}), \n",
    "                        index=None)\n",
    "\n",
    "df2 = pd.DataFrame(dict({'customer_id': [3, 5, 6, 7, 8],\n",
    "                         'age': [39, 24, 63, 43, 50]}), index=None)\n",
    "\n",
    "df_joined = pd.merge(df1, df2, how='inner', left_on='customer_id', right_on='customer_id')\n",
    "\n",
    "print('Original DataFrames')\n",
    "display(df1, df2)\n",
    "print(' ')\n",
    "print('Inner Join on Customer ID')\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Displaying DataFrames`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.zeros((100, 50), dtype=np.int64), index=None)\n",
    "\n",
    "pd.options.display.max_rows=10\n",
    "pd.options.display.max_columns=20\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows=None\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

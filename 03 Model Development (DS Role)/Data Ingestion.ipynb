{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Pandas DataFrame` \n",
    "\n",
    "* `Pandas I/O`\n",
    "\n",
    "* `Pandas Groupby` \n",
    "\n",
    "* `Pandas Concat and Merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pandas DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> A Pandas DataFrame is a two-dimensional, tabular data structure in the Python library Pandas, often used for data analysis and manipulation.   \n",
    "> It is similar to a spreadsheet in Excel or a SQL table and provides flexible and powerful ways to handle data.\n",
    "   \n",
    "> Here are some of the key features of a Pandas DataFrame:  \n",
    "\n",
    "> - **Rows and Columns:** A DataFrame consists of rows and columns, where each column has a name (column label) and each row has an index (row label).\n",
    "> - **Data Integration:** A DataFrame can read data from various sources like CSV files, Excel files, SQL databases, JSON files, and more.\n",
    "> - **Data Manipulation**: You can add, remove, or rename columns, filter data, group, aggregate, and merge data.\n",
    "> - **Flexibility**: A DataFrame can contain different data types in different columns, such as numerical values, strings, dates, and more.\n",
    "\n",
    "> For full documentation please see: [Pandas User Guide](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create <u>empty</u> Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create <u>empty</u> Pandas DataFrame <u>with row and column labels</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=[1, 2, 3], columns=[\"Column1\", \"Column2\", \"Column3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataFrame <u>with example data</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = {\n",
    "  \"Name\": {\n",
    "    \"0\": \"Alice\",\n",
    "    \"1\": \"Bob\",\n",
    "    \"2\": \"Charlie\",\n",
    "    \"3\": \"David\",\n",
    "    \"4\": \"Eva\"\n",
    "  },\n",
    "  \"Age\": {\n",
    "    \"0\": 24,\n",
    "    \"1\": 27,\n",
    "    \"2\": 22,\n",
    "    \"3\": 32,\n",
    "    \"4\": 29\n",
    "  },\n",
    "  \"City\": {\n",
    "    \"0\": \"New York\",\n",
    "    \"1\": \"Los Angeles\",\n",
    "    \"2\": \"Chicago\",\n",
    "    \"3\": \"Houston\",\n",
    "    \"4\": \"Phoenix\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pandas I/O`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The pandas I/O API is a set of top level `reader` functions accessed like `pandas.read_csv()` that generally return a pandas object. \n",
    "> The corresponding `writer` functions are object methods that are accessed like `DataFrame.to_csv()`. \n",
    "\n",
    "> Below is a table containing just some examples for available `readers` and `writers`. \n",
    "\n",
    "> For full documentation please see: [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/io.html)\n",
    "\n",
    "| **Format** | **Reader** | **Writer** |\n",
    "|----------|----------|----------|\n",
    "| XLSX | read_excel | to_excel |\n",
    "| CSV | read_csv | to_csv |\n",
    "| JSON | read_json | to_json |\n",
    "| SQL | read_sql | to_sql | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `XLSX` **Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "xlsx_file_path = \"data/example.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer\n",
    "df.to_excel(xlsx_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader\n",
    "xlsx_df = pd.read_excel(xlsx_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(xlsx_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(xlsx_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `CSV` **Files** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "csv_file_path = \"data/example.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader\n",
    "csv_df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(csv_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `JSON` **Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "json_file_path = \"data/example.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer\n",
    "df.to_json(json_file_path, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader\n",
    "json_df = pd.read_json(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(json_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `SQL` **Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymysql sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Create connection</u> to saklia MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"localhost\"\n",
    "user = \"root\"\n",
    "password = pd.read_json(\"config/database_config\")[\"password\"][0]\n",
    "database = \"sakila\"\n",
    "\n",
    "# Connection string\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}/{database}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Read data</u> from sakila MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM actor;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = pd.read_sql(sql=query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sql_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Write data</u> to sakila MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records = {\n",
    "  \"first_name\": {\n",
    "    \"0\": \"John\",\n",
    "    \"1\": \"Leonardo\",\n",
    "    \"2\": \"Brad\",\n",
    "    \"3\": \"Matt\",\n",
    "    \"4\": \"Edward\"\n",
    "  },\n",
    "  \"last_name\": {\n",
    "    \"0\": \"Travolta\",\n",
    "    \"1\": \"Di Caprio\",\n",
    "    \"2\": \"Pitt\",\n",
    "    \"3\": \"Damon\",\n",
    "    \"4\": \"Norton\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_records = pd.DataFrame(new_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_new_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_records.to_sql(name=\"t_actor\", con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ HINT:\n",
    "\n",
    "You can create the database table `t_actor` in your MySQL workbench using the follwing sql statement:\n",
    "\n",
    "```sql\n",
    "USE sakila;\n",
    "\n",
    "CREATE TABLE t_actor (\n",
    "    first_name VARCHAR(255),\n",
    "    last_name VARCHAR(255)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pandas Groupby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A groupby operation involves some combination of splitting the object, applying a function, and combining the results.   \n",
    "> This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "> For full documentation please see: [Pandas User Guide](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataFrame with products and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products\n",
    "products = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "# Dates ranging from 2023-01-01 to 2023-12-31\n",
    "dates = pd.date_range(start='2023-01-01', end='2023-12-31')\n",
    "\n",
    "# Cartesian product\n",
    "df = pd.DataFrame([(product, date) for product in products for date in dates],\n",
    "                  columns=['product', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "print(f\"df contains {len(products)} x {len(dates)} = {len(df)} rows\")\n",
    "display(df.head(5))\n",
    "display(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract quarter, month, week and weekday from dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarter\n",
    "df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "# Month\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "# Week\n",
    "df[\"week\"] = df[\"date\"].dt.isocalendar().week\n",
    "# Weekday\n",
    "df[\"weekday\"] = df[\"date\"].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(5))\n",
    "display(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column with random sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Random seed for reproducability\n",
    "np.random.seed(42)\n",
    "\n",
    "# Random sales\n",
    "df[\"sales\"] = np.random.randint(10000, 50000, size=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(5))\n",
    "display(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NaN values\n",
    "num_nan = 95\n",
    "\n",
    "# Random seed for reproducability\n",
    "np.random.seed(42)\n",
    "\n",
    "# Random indices to set as NaN\n",
    "nan_indices = np.random.choice(df.index, size=num_nan)\n",
    "\n",
    "# Replace with NaN\n",
    "df.loc[nan_indices, \"sales\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Aggregation operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Single</u> Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum\n",
    "df_sum = df.groupby(by=[\"product\"], as_index=False)[\"sales\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "df_mean = df.groupby(by=[\"product\"], as_index=False)[\"sales\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median\n",
    "df_median = df.groupby(by=[\"product\"], as_index=False)[\"sales\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum\n",
    "df_min = df.groupby(by=[\"quarter\"], as_index=False)[\"sales\"].min()\n",
    "\n",
    "# Maximum\n",
    "df_max = df.groupby(by=[\"quarter\"], as_index=False)[\"sales\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size (missing values included)\n",
    "df_size = df.groupby(by=[\"month\"], as_index=False)[\"sales\"].size()\n",
    "\n",
    "# Count (missing values excluded)\n",
    "df_count = df.groupby(by=[\"month\"], as_index=False)[\"sales\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values count\n",
    "df_nunique = df.groupby(by=[\"product\"], as_index=False)[\"week\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_nunique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Multiple </u> Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(by=[\"weekday\"], as_index=False).agg(\n",
    "    {\"sales\": [\"count\", \"min\", \"mean\", \"median\", \"max\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Custom</u> Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function\n",
    "def range_func(x):\n",
    "    return x.max() - x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom_agg = df.groupby(by=[\"weekday\"], as_index=False).agg(\n",
    "    {\"sales\": [\"count\", \"min\", \"mean\", \"median\", \"max\", range_func]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_custom_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation with <u>multiple group columns</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_multiple = df.groupby(by=[\"product\", \"weekday\"], as_index=False).agg(\n",
    "    {\"sales\": [\"count\", \"min\", \"mean\", \"median\", \"max\", range_func]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_agg_multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Rolling</u> Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling_agg = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Sum, Mean, Std Deviation\n",
    "result = df[\"sales\"].rolling(window=3).agg([\"sum\", \"mean\", \"std\"])\n",
    "\n",
    "df_rolling_agg[[\"sales_roll_sum_3\", \"sales_roll_mean_3\", \"sales_roll_std_3\"]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_rolling_agg.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pandas Concat and Merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Concat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Concatenate pandas objects along a particular axis.\n",
    "\n",
    "> For full documentation please see: [Pandas User Guide](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide `df` into three sub datasets - one per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = df.loc[df[\"product\"] == \"A\"]\n",
    "df_B = df.loc[df[\"product\"] == \"B\"]\n",
    "df_C = df.loc[df[\"product\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_A.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_B.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_C.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Concatenation operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack DataFrames with <u>identical columns</u> on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat(objs=[df_A, df_B, df_C], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_concat.head(5))\n",
    "display(df_concat.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack DataFrames with <u>overlapping columns</u> on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_C_drop = df_C.drop(columns=[\"quarter\", \"month\", \"week\", \"weekday\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_C_drop.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat_with_nan = pd.concat(objs=[df_A, df_B, df_C_drop], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_concat_with_nan.head(5))\n",
    "display(df_concat_with_nan.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append a <u>single row to the end</u> of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.Series(\n",
    "    {\n",
    "        \"product\": \"A\",\n",
    "        \"date\": pd.to_datetime(\"2024-01-01\"),\n",
    "        \"quarter\": 1,\n",
    "        \"month\": 1,\n",
    "        \"week\": 52,\n",
    "        \"weekday\": 0,\n",
    "        \"sales\": 99999.0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_new_row = pd.concat([df_A, new_row.to_frame().T], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_A_new_row.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Merge DataFrame or named Series objects with a database-style join.\n",
    "\n",
    "> For full documentation please see: [Pandas User Guide](https://pandas.pydata.org/docs/reference/api/pandas.merge.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`LEFT JOIN`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to select all <u>ACTION</u> movies from sakila database joining the follwing database tables:**\n",
    "\n",
    "* **`film`**: contains columns `film_id`, `title`,  ...  \n",
    "\n",
    "* **`category`**: contains columns `category_id`, `name`\n",
    "\n",
    "* **`film_category`**: contains columns `film_id`, `category_id`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_film = \"SELECT film_id, title FROM film;\"\n",
    "query_category = \"SELECT category_id, name FROM category;\"\n",
    "query_film_category = \"SELECT film_id, category_id FROM film_category;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film = pd.read_sql(sql=query_film, con=engine)\n",
    "df_category = pd.read_sql(sql=query_category, con=engine)\n",
    "df_film_category = pd.read_sql(sql=query_film_category, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_film.head(5))\n",
    "display(df_category.head(5))\n",
    "display(df_film_category.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Perform **`LEFT JOIN`** to join `category_id` from `film_category` table to `film` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = pd.merge(\n",
    "    # Left table\n",
    "    left=df_film,\n",
    "    # Right table\n",
    "    right=df_film_category,\n",
    "    # Join type\n",
    "    how=\"left\",\n",
    "    # Join key of left table\n",
    "    left_on=\"film_id\",\n",
    "    # Join key of right table\n",
    "    right_on=\"film_id\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_joined.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Perform another **`LEFT JOIN`** to join `name` from `category` to the joined table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = pd.merge(\n",
    "    # Left table\n",
    "    left=df_joined,\n",
    "    # Right table\n",
    "    right=df_category,\n",
    "    # Join type\n",
    "    how=\"left\",\n",
    "    # Join key of left table\n",
    "    left_on=\"category_id\",\n",
    "    # Join key of right table\n",
    "    right_on=\"category_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_joined.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Select <u>action</u> movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action_movies = df_joined.loc[df_joined[\"name\"] == \"Action\", :].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sakila database contains {len(df_action_movies)} action movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_action_movies.head(5))\n",
    "display(df_action_movies.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`INNER JOIN`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We want to select all <u>FILMS</u> with actor <u>CATE HARRIS</u> from sakila database joining the follwing database tables:**\n",
    "\n",
    "* **`film`**: contains columns `film_id`, `title`,  ...  \n",
    "\n",
    "* **`film_actor`**: contains columns `actor_id`, `film_id`  \n",
    "\n",
    "* **`actor`**: contains columns `actor_id`, `first_name`, `last_name`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>film_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actor_id  film_id             title\n",
       "0         1        1  ACADEMY DINOSAUR\n",
       "1        10        1  ACADEMY DINOSAUR\n",
       "2        20        1  ACADEMY DINOSAUR\n",
       "3        30        1  ACADEMY DINOSAUR\n",
       "4        40        1  ACADEMY DINOSAUR"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Films (with actors)\n",
    "query_film_actor = \"\"\"\n",
    "SELECT a.actor_id, a.film_id, b.title \n",
    "FROM film_actor as a\n",
    "LEFT JOIN film as b\n",
    "ON a.film_id = b.film_id;\n",
    "\"\"\"\n",
    "\n",
    "df_film_actor = pd.read_sql(sql=query_film_actor, con=engine)\n",
    "\n",
    "display(df_film_actor.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actor_id first_name last_name\n",
       "0       141       CATE    HARRIS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actors\n",
    "query_actor = \"\"\"\n",
    "SELECT actor_id, first_name, last_name \n",
    "FROM actor\n",
    "WHERE first_name = \"CATE\" AND last_name = \"HARRIS\";\n",
    "\"\"\"\n",
    "\n",
    "df_actor = pd.read_sql(sql=query_actor, con=engine)\n",
    "\n",
    "display(df_actor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Perform **`INNER JOIN`** to only return `film_id`s from `film_actor` table that correspond with `actor_id`s present in `actor` table  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris_movies = pd.merge(\n",
    "    # Left table\n",
    "    left=df_film_actor,\n",
    "    # Right table\n",
    "    right=df_actor,\n",
    "    # Join type\n",
    "    how=\"inner\",\n",
    "    # Join key of left table\n",
    "    left_on=\"actor_id\",\n",
    "    # Join key of right table\n",
    "    right_on=\"actor_id\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sakila database contains 28 movies with actor CATE HARRIS\n"
     ]
    }
   ],
   "source": [
    "print(f\"sakila database contains {len(df_harris_movies)} movies with actor CATE HARRIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>film_id</th>\n",
       "      <th>title</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>43</td>\n",
       "      <td>ATLANTIS CAUSE</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141</td>\n",
       "      <td>67</td>\n",
       "      <td>BERETS AGENT</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>188</td>\n",
       "      <td>CRAZY HOME</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>191</td>\n",
       "      <td>CROOKED FROGMEN</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>207</td>\n",
       "      <td>DANGEROUS UPTOWN</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actor_id  film_id             title first_name last_name\n",
       "0       141       43    ATLANTIS CAUSE       CATE    HARRIS\n",
       "1       141       67      BERETS AGENT       CATE    HARRIS\n",
       "2       141      188        CRAZY HOME       CATE    HARRIS\n",
       "3       141      191   CROOKED FROGMEN       CATE    HARRIS\n",
       "4       141      207  DANGEROUS UPTOWN       CATE    HARRIS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>film_id</th>\n",
       "      <th>title</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>141</td>\n",
       "      <td>849</td>\n",
       "      <td>STORM HAPPINESS</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>141</td>\n",
       "      <td>862</td>\n",
       "      <td>SUMMER SCARFACE</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>141</td>\n",
       "      <td>863</td>\n",
       "      <td>SUN CONFESSIONS</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>141</td>\n",
       "      <td>909</td>\n",
       "      <td>TREASURE COMMAND</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>141</td>\n",
       "      <td>992</td>\n",
       "      <td>WRATH MILE</td>\n",
       "      <td>CATE</td>\n",
       "      <td>HARRIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actor_id  film_id             title first_name last_name\n",
       "23       141      849   STORM HAPPINESS       CATE    HARRIS\n",
       "24       141      862   SUMMER SCARFACE       CATE    HARRIS\n",
       "25       141      863   SUN CONFESSIONS       CATE    HARRIS\n",
       "26       141      909  TREASURE COMMAND       CATE    HARRIS\n",
       "27       141      992        WRATH MILE       CATE    HARRIS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_harris_movies.head(5))\n",
    "display(df_harris_movies.tail(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

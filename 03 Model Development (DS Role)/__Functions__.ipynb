{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run config/seaborn_config.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Frame structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataframe(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Explore the structure and content of a Pandas DataFrame.\n",
    "\n",
    "    This function provides an overview of the given DataFrame, including:\n",
    "    - The shape of the DataFrame (number of rows and columns).\n",
    "    - The number of rows and columns.\n",
    "    - The data types of each column.\n",
    "    - Displays the first record in the DataFrame.\n",
    "    - Displays the last record in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame to be explored.\n",
    "\n",
    "    Returns:\n",
    "    None: This function prints out the structure and displays example records of the DataFrame.\n",
    "    \"\"\"\n",
    "    # Shape of the dataframe\n",
    "    print(\"Shape of the DataFrame:\", data.shape, \"\\n\")\n",
    "    \n",
    "    # Number of rows and columns\n",
    "    print(f\"df contains {len(data)} rows.\")\n",
    "    print(f\"df contains {len(data.columns)} columns:\", \"\\n\")\n",
    "    \n",
    "    # List of columns with data type of each column\n",
    "    print(data.dtypes)\n",
    "    \n",
    "    # Display first record\n",
    "    print(\"\\nFirst record:\")\n",
    "    display(data.head(1))\n",
    "    \n",
    "    # Display last record\n",
    "    print(\"\\nLast record:\")\n",
    "    display(data.tail(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Column type mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_column_types(data: pd.DataFrame, column_type_mapping: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Change the data types of DataFrame columns based on a provided mapping.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame whose column types need to be changed.\n",
    "    column_type_mapping (dict): A dictionary where keys are column names and values are the target data types.\n",
    "\n",
    "    Returns:\n",
    "    mapped_data (pd.DataFrame): The DataFrame with updated column types.\n",
    "    \"\"\"\n",
    "    # Print column types before mapping\n",
    "    print(\"Column types before mapping\")\n",
    "    print(data.dtypes, \"\\n\")\n",
    "\n",
    "    # Map column types\n",
    "    mapped_data = data.astype(column_type_mapping)\n",
    "\n",
    "    # Print column types after mapping\n",
    "    print(\"Column types after mapping\")\n",
    "    print(mapped_data.dtypes)\n",
    "\n",
    "    return mapped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seperate columns by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_columns_by_type(data: pd.DataFrame, primary_key: list):\n",
    "    \"\"\"\n",
    "    Selects and prints the categorical and numerical columns from a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to analyze.\n",
    "    \n",
    "    Returns:\n",
    "    A tuple containing separate lists for categorical, numerical and text columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select categorical columns\n",
    "    categorical_cols = data.select_dtypes(include=\"category\").columns.to_list()\n",
    "    \n",
    "    # Select numerical columns\n",
    "    numerical_cols = data.select_dtypes(include=\"number\").columns.to_list()\n",
    "\n",
    "    # Select text columns:\n",
    "    text_cols = data.select_dtypes(include=\"string\").columns.to_list()\n",
    "\n",
    "    # Select key columns:\n",
    "    key_cols = primary_key\n",
    "\n",
    "    # Remove key columns from other lists\n",
    "    for col in key_cols:\n",
    "        try:\n",
    "            categorical_cols.remove(col)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            numerical_cols.remove(col)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            text_cols.remove(col)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Print lists\n",
    "    print(\"Key Columns:\", key_cols)    \n",
    "    print(\"Categorical Columns:\", categorical_cols)\n",
    "    print(\"Numerical Columns:\", numerical_cols)\n",
    "    print(\"Text Columns:\", text_cols)\n",
    "    \n",
    "    return key_cols, categorical_cols, numerical_cols, text_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_missing_values(data: pd.DataFrame, show_all: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Explore missing values in a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame to analyze.\n",
    "    show_all (bool): A boolean to indicate whether columns without missing values should be included in the output.\n",
    "\n",
    "    Returns:\n",
    "    missing_summary (pd.DataFrame): A DataFrame summarizing the number and percentage of missing values for each column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the number of missing values per column\n",
    "    missing_count = data.isnull().sum()\n",
    "\n",
    "    # Calculate the percentage of missing values per column\n",
    "    missing_percentage = (missing_count / len(data)) * 100\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    missing_summary = pd.DataFrame(\n",
    "        {\"Missing Count\": missing_count, \"Missing Percentage\": missing_percentage}\n",
    "    )\n",
    "\n",
    "    # Filter out columns with no missing values for better readability\n",
    "    if show_all == False:\n",
    "        missing_summary = missing_summary[missing_summary[\"Missing Count\"] > 0]\n",
    "\n",
    "    # Sort the summary by the highest percentage of missing values\n",
    "    missing_summary = missing_summary.sort_values(\n",
    "        by=\"Missing Percentage\", ascending=False\n",
    "    )\n",
    "\n",
    "    return missing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_values(\n",
    "    data: pd.DataFrame, columns_to_drop: list, how: str = \"any\", axis: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Remove rows or columns with missing values from a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame to clean.\n",
    "    how (str): Determine if row/column is removed when it contains missing data:\n",
    "               - \"any\": If any NA values are present, drop that row/column.\n",
    "               - \"all\": If all values are NA, drop that row/column.\n",
    "               - \"list\": Remove user-defined list of columns.\n",
    "    axis (int): Determine if rows or columns are removed:\n",
    "                - 0: Drop rows with missing values.\n",
    "                - 1: Drop columns with missing values.\n",
    "    columns: User-defined list of columns to drop.\n",
    "\n",
    "    Returns:\n",
    "    cleaned_data (pd.DataFrame): The cleaned DataFrame with missing values removed.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Number of records after missing value removal: {len(data)}\")\n",
    "\n",
    "    # Remove rows or columns with missing values\n",
    "    if how in (\"any\", \"all\") and axis in (0, 1):\n",
    "        cleaned_data = data.dropna(how=how, axis=axis)\n",
    "        \n",
    "    elif how == \"list\" and axis == 1:\n",
    "        cleaned_data = data.drop(columns=columns_to_drop, axis=1)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"When 'how' is 'list', axis must be '1'.\")\n",
    "    \n",
    "    print(f\"Number of records after missing value removal: {len(cleaned_data)}\")\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to explore outliers (and extreme values) for continuous variables\n",
    "def explore_outliers(data: pd.DataFrame, columns: list, method: str = \"iqr\"):\n",
    "    \"\"\"\n",
    "    Explore outliers (and extreme values) for a continuous variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "    categorical_columns (list): List of categorical column names.\n",
    "    method (str): The method to be used to determine outliers.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "\n",
    "        # Plot the boxplot\n",
    "        plot_boxplot(data, col)\n",
    "\n",
    "        # Adds outlier statistics to the boxplot\n",
    "        add_outlier_statistics(data, col, method)\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to plot a boxplot\n",
    "def plot_boxplot(data, col):\n",
    "    \"\"\"\n",
    "    Plot a boxplot for a continuous variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data.\n",
    "    col (str): The name of the continuous variable.\n",
    "    \"\"\"\n",
    "    # Create boxplot\n",
    "    sns.boxplot(x=col, data=data[data[col].notnull()], width=0.5, color=custom_colors[\"blue\"])\n",
    "\n",
    "    # Add plot aesthetics\n",
    "    plt.title(f\"Boxplot of **{col}**\")\n",
    "    plt.xlabel(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to add outlier statistics to boxplot\n",
    "def add_outlier_statistics(data: pd.DataFrame, col: str, method: str):\n",
    "    \"\"\"Adds outlier statistics to the boxplot.\"\"\"\n",
    "    # Calculate number and share of outliers\n",
    "    n = len(data[col][data[col].notnull()])\n",
    "\n",
    "    if method == \"iqr\":\n",
    "        n_outliers = n - len(remove_outliers_from_column(data, col, method))\n",
    "        pct_outliers = n_outliers / n * 100\n",
    "    \n",
    "    # Add number and share of outliers to the plot\n",
    "    if pct_outliers == 0:\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.90,\n",
    "            s=f\"Outliers: {n_outliers}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=basic_colors[\"black\"],\n",
    "        )\n",
    "\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.85,\n",
    "            s=f\"Outliers %: {pct_outliers:.1f}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=basic_colors[\"black\"],\n",
    "        )\n",
    "    \n",
    "    elif pct_outliers > 0 and pct_outliers < 10:\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.90,\n",
    "            s=f\"Outliers: {n_outliers}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=custom_colors[\"orange\"],\n",
    "        )\n",
    "\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.85,\n",
    "            s=f\"Outliers %: {pct_outliers:.1f}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=custom_colors[\"orange\"],\n",
    "        )\n",
    "    else:\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.90,\n",
    "            s=f\"Outliers: {n_outliers}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=custom_colors[\"red\"],\n",
    "        )\n",
    "\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.85,\n",
    "            s=f\"Outliers %: {pct_outliers:.1f}\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=custom_colors[\"red\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove outliers from continuous variable\n",
    "def remove_outliers_from_column(\n",
    "    data: pd.DataFrame, col: str, method: str = \"iqr\"\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Removes outliers from a continuous variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input DataFrame.\n",
    "    col (str): The name of the column to remove outliers from.\n",
    "    method (str): The method to be used to remove outliers.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A pandas Series with outliers removed from the specified column.\n",
    "    \"\"\"\n",
    "\n",
    "    if method == \"iqr\":\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "\n",
    "        # Calculate the Interquartile Range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the bounds for non-outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Filter the data to remove outliers\n",
    "        filtered_series = data[col][\n",
    "            (data[col] >= lower_bound) & (data[col] <= upper_bound)\n",
    "        ]\n",
    "\n",
    "    return filtered_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_from_dataframe(data: pd.DataFrame, cols: list, method=\"iqr\"):\n",
    "    \"\"\"\n",
    "    Remove outliers from specified columns in a pandas DataFrame using the IQR method.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame from which to remove outliers.\n",
    "    columns (list): A list of column names from which to remove outliers.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with outliers removed from specified columns.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Number of records before outlier removal: {len(data)}\")\n",
    "\n",
    "    # Make copy of the input data\n",
    "    cleaned_data = data.copy()  \n",
    "\n",
    "    if method == \"iqr\":\n",
    "        for col in cols:\n",
    "            if col in cleaned_data.columns:\n",
    "                # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "                Q1 = cleaned_data[col].quantile(0.25)\n",
    "                Q3 = cleaned_data[col].quantile(0.75)\n",
    "\n",
    "                # Calculate IQR\n",
    "                IQR = Q3 - Q1\n",
    "\n",
    "                # Define the bounds for outliers\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "                # Remove outliers\n",
    "                cleaned_data = cleaned_data[\n",
    "                    (cleaned_data[col] >= lower_bound)\n",
    "                    & (cleaned_data[col] <= upper_bound)\n",
    "                ]\n",
    "\n",
    "    print(f\"Number of records after outlier removal: {len(cleaned_data)}\")\n",
    "\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Univariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def explore_univariate(\n",
    "    data: pd.DataFrame,\n",
    "    columns: list,\n",
    "    dist_type: str,\n",
    "    relative_frequency: bool = True,\n",
    "    n_bins: int = 20,\n",
    "    remove_outliers: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main function to explore univariate distributions (discrete or continuous).\n",
    "\n",
    "    Args:\n",
    "    - data: A pandas DataFrame.\n",
    "    - columns: A list of column names to explore.\n",
    "    - dist_type: Distribution type: \"discrete\" or \"continuous\".\n",
    "    - relative_frequency: If True, use relative frequencies for discrete variables.\n",
    "    - n_bins: Number of bins for continuous distributions.\n",
    "    - remove_outliers: Boolean to indicate if outliers should be removed from continuous variables before plotting.\n",
    "    \"\"\"\n",
    "    if dist_type == \"discrete\":\n",
    "        for col in columns:\n",
    "            # Explore discrete variable\n",
    "            explore_discrete(data, col, relative_frequency)\n",
    "\n",
    "    elif dist_type == \"continuous\":\n",
    "        for col in columns:\n",
    "            # Explore continuous variable\n",
    "            explore_continuous(data, col, n_bins, remove_outliers)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"dist_type must be either 'discrete' or 'continuous'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_discrete(data: pd.DataFrame, col: str, relative_frequency: bool):\n",
    "    \"\"\"\n",
    "    Function to explore the distribution of a discrete variable.\n",
    "\n",
    "    Args:\n",
    "    - data: A pandas DataFrame.\n",
    "    - col: The column to explore.\n",
    "    - relative_frequency: If True, use relative frequencies, otherwise use absolute.\n",
    "    \"\"\"\n",
    "    # Configure the barplot\n",
    "    stat, fmt, ylim = configure_barplot(data, col, relative_frequency)\n",
    "\n",
    "    # Plot the bar plot\n",
    "    plot_barplot(data, col, stat, ylim, fmt)\n",
    "\n",
    "    # Add cardinality information to the barplot\n",
    "    add_cardinality_info(data, col)\n",
    "\n",
    "    # Show the barplot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to configure barplot\n",
    "def configure_barplot(data: pd.DataFrame, col: str, relative_frequency: bool):\n",
    "    \"\"\"\n",
    "    Configure plot settings for discrete distributions.\n",
    "\n",
    "    Args:\n",
    "    - data: A pandas DataFrame.\n",
    "    - col: The column to explore.\n",
    "    - relative_frequency: If True, use relative frequencies, otherwise absolute.\n",
    "\n",
    "    Returns:\n",
    "    - stat: Statistical option for seaborn plot.\n",
    "    - fmt: Format for bar labels.\n",
    "    - ylim: Upper limit for y-axis.\n",
    "    \"\"\"\n",
    "    # Configure stat, fmt, ylim\n",
    "    if relative_frequency:\n",
    "        stat = \"probability\"\n",
    "        fmt = \"%.2f\"\n",
    "        ylim = 1\n",
    "        \n",
    "    else:\n",
    "        stat = \"count\"\n",
    "        fmt = \"%.0f\"\n",
    "        ylim = data[col].value_counts().max() * 1.2\n",
    "\n",
    "    return stat, fmt, ylim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to plot barplot\n",
    "def plot_barplot(data: pd.DataFrame, col: str, stat: str, ylim: float, fmt: str):\n",
    "    \"\"\"\n",
    "    Function to create a bar plot for the discrete variable.\n",
    "\n",
    "    Args:\n",
    "    - data: A pandas DataFrame.\n",
    "    - col: The column to explore.\n",
    "    - stat: Statistic to display ('count' or 'probability').\n",
    "    - ylim: Y-axis limit.\n",
    "    - fmt: Format for bar labels.\n",
    "    \"\"\"\n",
    "    # Create bar plot\n",
    "    ax = sns.histplot(\n",
    "        data=data,\n",
    "        x=col,\n",
    "        stat=stat,\n",
    "        discrete=True,\n",
    "        shrink=0.95,\n",
    "        alpha=0.50,\n",
    "        color=custom_colors[\"blue\"],\n",
    "    )\n",
    "\n",
    "    # Add value labels - if cardinality is not too high\n",
    "    if hasattr(ax, \"containers\") and data[col].nunique() <= 20:\n",
    "        for bar in ax.containers:\n",
    "            ax.bar_label(bar, fmt=fmt, fontsize=10)\n",
    "\n",
    "    # Add plot aesthetics\n",
    "    plt.title(f\"Distribution of **{col}**\")\n",
    "    plt.xlabel(col)\n",
    "    plt.xticks(data[col].unique().dropna().sort_values(ascending=True))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.ylim(0, ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to add cardinality information to barplot\n",
    "def add_cardinality_info(data: pd.DataFrame, col: str):\n",
    "    \"\"\"Adds cardinality information to the barplot.\"\"\"\n",
    "    # Calculate number of unique values\n",
    "    cardinality = data[col].nunique()\n",
    "    \n",
    "    # Add number of unique values to the plot\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.90,\n",
    "        s=f\"Unique values: {cardinality}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "\n",
    "    # Add indication for moderate or high cardinality to the plot\n",
    "    if cardinality >= 10 and cardinality < 50:\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.80,\n",
    "            s=\"Moderate Cardinality\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=custom_colors[\"orange\"],\n",
    "        )\n",
    "    elif cardinality >= 50:\n",
    "        plt.text(\n",
    "            x=1.02,\n",
    "            y=0.80,\n",
    "            s=\"High Cardinality\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            color=custom_colors[\"red\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactored function to explore continuous variables\n",
    "def explore_continuous(data: pd.DataFrame, col: str, n_bins: int, remove_outliers: bool):\n",
    "    \"\"\"\n",
    "    Function to explore the distribution of a continuous variable.\n",
    "\n",
    "    Args:\n",
    "    - data: A pandas DataFrame.\n",
    "    - col: The column to explore.\n",
    "    - n_bins: Number of bins to use for the histogram.\n",
    "    - remove_outliers: Boolean to indicat if outliers should be removed before plotting.\n",
    "    \"\"\"\n",
    "    # Make a copy of the data\n",
    "    copied_data = data.copy()\n",
    "\n",
    "    # Remove outliers\n",
    "    if remove_outliers == True:\n",
    "        copied_data[col] = remove_outliers_iqr(copied_data, col)[2]\n",
    "    \n",
    "    # Calculate continuous statistics\n",
    "    stats = calculate_continuous_stats(copied_data, col)\n",
    "\n",
    "    # Plot the histplot\n",
    "    plot_histplot(copied_data, col, n_bins)\n",
    "\n",
    "    # Add the continuous stats information\n",
    "    add_continuous_stats_info(stats)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to calculate continuous statistics\n",
    "def calculate_continuous_stats(data: pd.DataFrame, col: str):\n",
    "    \"\"\"\n",
    "    Calculate basic statistics for a continuous variable.\n",
    "\n",
    "    Args:\n",
    "    - data: A pandas DataFrame.\n",
    "    - col: The column to calculate statistics for.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary of calculated statistics.\n",
    "    \"\"\"\n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        \"min\": data[col].min(),\n",
    "        \"max\": data[col].max(),\n",
    "        \"mean\": data[col].mean(),\n",
    "        \"median\": data[col].median(),\n",
    "        \"mode\": data[col].mode()[0],\n",
    "        \"var\": data[col].var(),\n",
    "        \"std\": data[col].std(),\n",
    "        \"skew\": data[col].skew(),\n",
    "        \"kurt\": data[col].kurt(),\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to plot histplot\n",
    "def plot_histplot(data: pd.DataFrame, col: str, n_bins: int):\n",
    "    \"\"\"\n",
    "    Function to create a histogram plot for the continuous variable.\n",
    "\n",
    "    Args:\n",
    "    - data: A pandas DataFrame.\n",
    "    - col: The column to explore.\n",
    "    - n_bins: Number of bins to use for the histogram.\n",
    "    \"\"\"\n",
    "    # Create histogram\n",
    "    ax = sns.histplot(\n",
    "        data=data,\n",
    "        x=col,\n",
    "        bins=n_bins,\n",
    "        kde=True,\n",
    "        stat=\"probability\",\n",
    "        alpha=0.50,\n",
    "        color=custom_colors[\"blue\"],\n",
    "    )\n",
    "    \n",
    "    # Add plot aesthetics\n",
    "    plt.title(f\"Distribution of **{col}**\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to add statistical annotations to plots\n",
    "def add_continuous_stats_info(stats: dict):\n",
    "    \"\"\"\n",
    "    Add annotations (mean, median, etc.) to the plot.\n",
    "\n",
    "    Args:\n",
    "    - stats: A dictionary of calculated statistics.\n",
    "    \"\"\"\n",
    "    # Add statistical annotations to the plot\n",
    "    plt.axvline(\n",
    "        stats[\"mean\"],\n",
    "        color=\"#000000\",\n",
    "        linestyle=\"-\",\n",
    "        alpha=1.0,\n",
    "        label=f\"Mean: {stats['mean']:.1f}\",\n",
    "    )\n",
    "    plt.axvline(\n",
    "        stats[\"median\"],\n",
    "        color=\"#000000\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=1.00,\n",
    "        label=f\"Median: {stats['median']:.1f}\",\n",
    "    )\n",
    "    plt.axvline(\n",
    "        stats[\"mode\"],\n",
    "        color=\"#000000\",\n",
    "        linestyle=\":\",\n",
    "        alpha=1.00,\n",
    "        label=f\"Mode: {stats['mode']:.1f}\",\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.80,\n",
    "        s=f\"Min: {stats['min']:.1f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.75,\n",
    "        s=f\"Max: {stats['max']:.1f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.50,\n",
    "        s=f\"Variance: {stats['var']:.1f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.45,\n",
    "        s=f\"Std Dev: {stats['std']:.1f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.20,\n",
    "        s=f\"Skewness: {stats['skew']:.1f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.15,\n",
    "        s=f\"Kurtosis: {stats['kurt']:.1f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bivariate relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def explore_bivariate_relationships(\n",
    "    data: pd.DataFrame,\n",
    "    categorical_columns: list,\n",
    "    numerical_columns: list,\n",
    "    y_column: str,\n",
    "    y_type: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main function to explore bivariate relationships in a DataFrame based on the target variable's type.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "    categorical_columns (list): List of categorical column names.\n",
    "    numerical_columns (list): List of numerical column names.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    y_type (str): The type of the target variable ('continuous' or 'discrete').\n",
    "    \"\"\"\n",
    "    \n",
    "    if y_type == \"continuous\":\n",
    "        print(\"**Continuous features**\")\n",
    "        # Explore relationships between continuous features and a continuous target variable\n",
    "        explore_continuous_continuous(data, numerical_columns, y_column)\n",
    "        \n",
    "        print(\"**Discrete features**\")\n",
    "        # Explore relationship between discrete features and a continuous target variable\n",
    "        explore_continuous_discrete(data, categorical_columns, y_column)\n",
    "\n",
    "    elif y_type == \"discrete\":\n",
    "        print(\"**Continuous features**\")\n",
    "        # Explore relationship between continuous features and a discrete target variable\n",
    "        explore_discrete_continuous(data, numerical_columns, y_column)\n",
    "        \n",
    "        print(\"**Discrete features**\")\n",
    "        # Explore relationship between discrete features and a discrete target variable\n",
    "        explore_discrete_discrete(data, categorical_columns, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function for relationships between continuous features and a continuous target variable\n",
    "def explore_continuous_continuous(data, numerical_columns, y_column):\n",
    "    \"\"\"\n",
    "    Explore relationships between continuous features and a continuous target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "    numerical_columns (list): List of numerical column names.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    \"\"\"\n",
    "    for col in numerical_columns:\n",
    "        if col == y_column:\n",
    "            continue\n",
    "        \n",
    "        # Calculate correlation coefficients\n",
    "        pearson_corr, spearman_corr = calculate_correlation_coefficients(\n",
    "            data, col, y_column\n",
    "        )\n",
    "        # Plot the scatterplot\n",
    "        plot_scatterplot(data, col, y_column, pearson_corr, spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to calculate correlation coefficients\n",
    "def calculate_correlation_coefficients(data, col, y_column):\n",
    "    \"\"\"\n",
    "    Calculate Pearson and Spearman correlations.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data.\n",
    "    col (str): The name of the numerical feature column.\n",
    "    y_column (str): The name of the target variable column.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Pearson and Spearman correlation coefficients.\n",
    "    \"\"\"\n",
    "    # Calculate Pearson correlation\n",
    "    pearson_corr = data[col].corr(data[y_column], method=\"pearson\")\n",
    "\n",
    "    # Calculate Spearman correlation\n",
    "    spearman_corr = data[col].corr(data[y_column], method=\"spearman\")\n",
    "    \n",
    "    return pearson_corr, spearman_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to plot a scatterplot\n",
    "def plot_scatterplot(data, col, y_column, pearson_corr, spearman_corr):\n",
    "    \"\"\"\n",
    "    Plot scatterplot for a continuous feature against the target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data.\n",
    "    col (str): The name of the numerical feature column.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    pearson_corr (float): Pearson correlation coefficient.\n",
    "    spearman_corr (float): Spearman correlation coefficient.\n",
    "    \"\"\"\n",
    "    # Create scatterplot\n",
    "    sns.regplot(\n",
    "        x=col,\n",
    "        y=y_column,\n",
    "        data=data,\n",
    "        ci=None,\n",
    "        marker=\"o\",\n",
    "        scatter_kws={\"s\": 50, \"alpha\": 0.10, \"color\": custom_colors[\"blue\"]},\n",
    "        line_kws={\"color\": basic_colors[\"black\"], \"linewidth\": 2, \"linestyle\": \"--\"},\n",
    "    )\n",
    "\n",
    "    # Add plot aesthetics\n",
    "    plt.title(f\"Scatterplot of **{col}** / **{y_column}**\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(y_column)\n",
    "\n",
    "    # Add annotations\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.90,\n",
    "        s=f\"Pearson: {pearson_corr:.2f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "    plt.text(\n",
    "        x=1.02,\n",
    "        y=0.85,\n",
    "        s=f\"Spearman: {spearman_corr:.2f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        color=\"#000000\",\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function for relationships between discrete features and a continuous target variable\n",
    "def explore_continuous_discrete(data, categorical_columns, y_column):\n",
    "    \"\"\"\n",
    "    Explore relationships between discrete features and a continuous target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "    categorical_columns (list): List of categorical column names.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    \"\"\"\n",
    "    # Calculate median of target variable\n",
    "    y_median = data[y_column].median()\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        # Plot the grouped boxplot\n",
    "        plot_grouped_boxplot(data, col, y_column, y_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to plot a boxplot\n",
    "def plot_grouped_boxplot(data, col, y_column, y_median):\n",
    "    \"\"\"\n",
    "    Plot a boxplot for a discrete feature against a continuous target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data.\n",
    "    col (str): The name of the categorical feature column.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    y_median (float): The median of the target variable.\n",
    "    \"\"\"\n",
    "    # Create boxplot\n",
    "    sns.boxplot(x=col, y=y_column, data=data, width=0.5, color=custom_colors[\"blue\"])\n",
    "\n",
    "    # Add plot aesthetics\n",
    "    plt.title(f\"Grouped Boxplot of **{col}** / **{y_column}**\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.axhline(\n",
    "        y=y_median, alpha=0.50, color=basic_colors[\"black\"], linestyle=\"--\", linewidth=2\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function for relationships between continuous features and a discrete target variable\n",
    "def explore_discrete_continuous(data, numerical_columns, y_column):\n",
    "    \"\"\"\n",
    "    Explore relationships between continuous features and a discrete target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "    numerical_columns (list): List of numerical column names.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    \"\"\"\n",
    "    for col in numerical_columns:\n",
    "        # Plot the grouped histplot\n",
    "        plot_grouped_histplot(data, col, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to plot a stacked histogram\n",
    "def plot_grouped_histplot(data, col, y_column):\n",
    "    \"\"\"\n",
    "    Plot a histogram for a continuous feature against a discrete target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data.\n",
    "    col (str): The name of the numerical feature column.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    \"\"\"\n",
    "    # Select colors from color palette based on number of categories\n",
    "    n_categories = data[y_column].nunique()\n",
    "    selected_colors = custom_qualitative_palette[:n_categories]\n",
    "    \n",
    "    # Create grouped histplot\n",
    "    sns.histplot(\n",
    "        data=data,\n",
    "        x=col,\n",
    "        hue=y_column,\n",
    "        kde=True,\n",
    "        stat=\"probability\",\n",
    "        bins=10,\n",
    "        common_norm=False,\n",
    "        alpha=0.50,\n",
    "        palette=selected_colors,\n",
    "    )\n",
    "\n",
    "    # Add plot aesthetics\n",
    "    plt.title(f\"Grouped Histplot of **{col}** / **{y_column}**\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(f\"Probability of {y_column}\")\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function for relationships between discrete features and a discrete target variable\n",
    "def explore_discrete_discrete(data, categorical_columns, y_column):\n",
    "    \"\"\"\n",
    "    Explore relationships between discrete features and a discrete target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "    categorical_columns (list): List of categorical column names.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    \"\"\"\n",
    "    for col in categorical_columns:\n",
    "        if col == y_column:\n",
    "            continue\n",
    "        \n",
    "        # Plot the stacked barplot\n",
    "        plot_stacked_barplot(data, col, y_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-function to plot a stacked barplot\n",
    "def plot_stacked_barplot(data, col, y_column):\n",
    "    \"\"\"\n",
    "    Plot a stacked bar chart for a discrete feature against a discrete target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the data.\n",
    "    col (str): The name of the categorical feature column.\n",
    "    y_column (str): The name of the target variable column.\n",
    "    \"\"\"\n",
    "    # Create a contingency table\n",
    "    cross_tab = pd.crosstab(data[col], data[y_column], normalize=\"index\")\n",
    "\n",
    "    # Select colors from color palette based on number of categories\n",
    "    n_categories = data[y_column].nunique()\n",
    "    selected_colors = custom_qualitative_palette[:n_categories]\n",
    "\n",
    "    # Create stacked bar plot\n",
    "    ax = cross_tab.plot(\n",
    "        kind=\"bar\", stacked=True, alpha=0.50, color=selected_colors\n",
    "    )\n",
    "\n",
    "    # Add value labels\n",
    "    if hasattr(ax, \"containers\"):\n",
    "        for bar in ax.containers:\n",
    "            ax.bar_label(bar, label_type=\"center\", fmt=\"%.2f\", fontsize=10)\n",
    "\n",
    "    # Add plot aesthetics\n",
    "    plt.title(f\"Stacked Barplot of **{col}** / **{y_column}**\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(f\"Probability of {y_column}\")\n",
    "    plt.legend(title=y_column, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.xticks(rotation=0)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
